{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os, sys, numpy as np, pandas as pd, tensorflow as tf, re, codecs, seaborn as sns, json, time, csv, datetime as dt\n",
    "import pickle, collections, random, math, numbers, scipy.sparse as sp, matplotlib.pyplot as plt, scipy.sparse as sp\n",
    "\n",
    "from pprint import pprint\n",
    "from tensorflow.contrib.training.python.training.hparam import HParams\n",
    "\n",
    "def reload(mName):\n",
    "    import importlib\n",
    "    if mName in sys.modules:\n",
    "        del sys.modules[mName]\n",
    "    return importlib.import_module(mName)\n",
    "\n",
    "\n",
    "from collections import deque, defaultdict, OrderedDict\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, minmax_scale\n",
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# classpath\n",
    "# ctx = os.path.abspath('..').replace('\\\\', '/')\n",
    "ctx = 'D:/Python/notebook/restful'\n",
    "cps = [ctx]\n",
    "_ = [sys.path.insert(0, cp) for cp in cps if cp not in sys.path]\n",
    "\n",
    "# data path\n",
    "datapath = '/'.join([ctx, 'repo', 'data'])\n",
    "\n",
    "seed = 88\n",
    "utils = reload('recomm.trainer.utils.utils')\n",
    "np.set_printoptions(precision=4, suppress=True, linewidth=100)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "ratings = pd.read_csv(\"{}/ml-latest-small/ratings.csv\".format(datapath))\n",
    "ratings['timestamp'] = ratings.timestamp.map(dt.datetime.fromtimestamp).map(str)\n",
    "ratings['ori_rating'] = ratings['rating']\n",
    "ratings['rating'] = (ratings.rating >= 4).astype(int)\n",
    "tr, te = utils.split_by_ratio(ratings)\n",
    "\n",
    "movies = pd.read_csv(\"{}/ml-latest-small/movies.csv\".format(datapath))\n",
    "avg_rt = ratings.groupby(\"movieId\", as_index=False).ori_rating.mean().rename(index=str, columns={'ori_rating': 'avg_rating'})\n",
    "movies = movies.merge(avg_rt, how='left', on='movieId')\n",
    "# movies.avg_rating.fillna(ratings.rating.mean())\n",
    "movies[\"year\"] = movies.title.str.findall(\"\\(\\s*(\\d+)\\s*\\)\").map(lambda lst: int(lst[-1]) if len(lst) else None)\n",
    "# movies[\"year\"] = minmax_scale(movies.year.fillna(movies.year.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data, movie_trans, train_hist=None, is_train=True):\n",
    "    queue = []\n",
    "    data = data.merge(movie_trans, how=\"left\", on=\"movieId\")\n",
    "    columns=[\"user_id\", \"query_movie_ids\",\n",
    "             \"genres\", \"avg_rating\", \"year\", \"candidate_movie_id\",\n",
    "             \"timestamp\",\n",
    "             \"rating\"]\n",
    "    \n",
    "    list2str = lambda lst: ','.join(map(str, lst))\n",
    "    for u, df in data.groupby(\"userId\"):\n",
    "        df = df.sort_values(\"rating\", ascending=False)\n",
    "        if not is_train:\n",
    "            user_movies_hist = train_hist.query(\"userId == {}\".format(u)).movieId\n",
    "        for i, (_, r) in enumerate(df.iterrows()):\n",
    "            if is_train:\n",
    "                query_hist = df.movieId[:i].tolist() + df.movieId[i + 1:].tolist()\n",
    "                query_hist = list2str(query_hist)\n",
    "                queue.append([int(r.userId), query_hist, r.genres, r.avg_rating, r.year, int(r.movieId), r.timestamp, r.rating])\n",
    "            else:\n",
    "                tr_hist = set(user_movies_hist.tolist())\n",
    "                query_hist = list(tr_hist - set([int(r.movieId)]))\n",
    "                query_hist = list2str(query_hist)\n",
    "                queue.append([int(r.userId), query_hist, r.genres, r.avg_rating, r.year, int(r.movieId), r.timestamp, r.rating])\n",
    "    return pd.DataFrame(queue, columns=columns)\n",
    "    \n",
    "tr_merged = preprocess(tr, movies)\n",
    "tr_merged.to_csv('./tr.raw.movielens.csv', index=False, header=None)\n",
    "\n",
    "te_merged = preprocess(te, movies, tr, is_train=False)\n",
    "te_merged.to_csv('./te.raw.movielens.csv', index=False, header=None)\n",
    "# 合併成一個檔案\n",
    "merged = pd.concat([tr_merged, te_merged], ignore_index=True)\n",
    "merged.to_csv('./merged_movielens.csv', index=False, header=None)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Cmd Submit Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cd D:/Python/notebook/recomm_prod && \\\n",
    "gcloud ml-engine jobs submit training recomm_movielens_15 \\\n",
    "    --job-dir gs://recomm-job/foo/model \\\n",
    "    --runtime-version 1.4 \\\n",
    "    --module-name trainer.ctrl \\\n",
    "    --package-path trainer \\\n",
    "    --region asia-east1 \\\n",
    "    --config config.yaml \\\n",
    "    -- \\\n",
    "    --method train \\\n",
    "    --conf-path gs://recomm-job/foo/data/user_supplied/movielens.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!gcloud ml-engine jobs describe recomm_movielens_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Cloud Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils = reload('recomm.trainer.utils.utils')\n",
    "env = reload('recomm.trainer.env')\n",
    "flex = reload('recomm.trainer.utils.flex')\n",
    "service = reload('recomm.trainer.service')\n",
    "\n",
    "ctrl = reload('recomm.trainer.ctrl').Ctrl.instance\n",
    "params = dict(conf_path='gs://movielens-foo/user_supplied/movielens.yaml')\n",
    "ctrl.gen_data(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud View Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-13 17:31:40,947 - Loader - INFO [line:365] - try to unserialize from gs://recomm-job/foo-bar/movielens_recommendation/data/parsed.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'col_states_': OrderedDict([('query_movie_ids',\n",
       "               CatgMapper(allow_null=True, default=None, is_multi=True,\n",
       "                     name='query_movie_ids', sep=',', vocabs=None, vocabs_path=None)),\n",
       "              ('genres',\n",
       "               CatgMapper(allow_null=True, default=None, is_multi=True, name='genres',\n",
       "                     sep='|', vocabs=None, vocabs_path=None)),\n",
       "              ('avg_rating', NumericMapper(default=None, name='avg_rating')),\n",
       "              ('year', NumericMapper(default=None, name='year')),\n",
       "              ('candidate_movie_id',\n",
       "               CatgMapper(allow_null=True, default=None, is_multi=False,\n",
       "                     name='candidate_movie_id', sep=None, vocabs=None, vocabs_path=None)),\n",
       "              ('rating',\n",
       "               CatgMapper(allow_null=False, default=None, is_multi=False, name='rating',\n",
       "                     sep=None, vocabs=None, vocabs_path=None))]),\n",
       " 'conf_': {'columns': [{'id': 'user_id', 'm_dtype': 'catg'},\n",
       "   {'id': 'query_movie_ids',\n",
       "    'is_multi': True,\n",
       "    'm_dtype': 'catg',\n",
       "    'sep': ',',\n",
       "    'vocabs_path': 'D:/Python/notebook/restful/repo/user_supplied/item.vocab'},\n",
       "   {'id': 'genres',\n",
       "    'is_multi': True,\n",
       "    'm_dtype': 'catg',\n",
       "    'sep': '|',\n",
       "    'vocabs_path': 'D:/Python/notebook/restful/repo/user_supplied/genres.vocab'},\n",
       "   {'id': 'avg_rating', 'm_dtype': 'cont'},\n",
       "   {'id': 'year', 'm_dtype': 'cont'},\n",
       "   {'id': 'candidate_movie_id',\n",
       "    'm_dtype': 'catg',\n",
       "    'vocabs_path': 'D:/Python/notebook/restful/repo/user_supplied/item.vocab'},\n",
       "   {'date_format': '%Y-%m-%d %H:%M:%S',\n",
       "    'id': 'timestamp',\n",
       "    'm_dtype': 'datetime'},\n",
       "   {'id': 'rating', 'm_dtype': 'catg'}],\n",
       "  'item': ['genres', 'avg_rating', 'year', 'candidate_movie_id'],\n",
       "  'label': ['rating'],\n",
       "  'model_id': 'movielens_recommendation',\n",
       "  'project_id': 'foo-bar',\n",
       "  'raw_dir': 'D:/Python/notebook/restful/repo/user_supplied/raws',\n",
       "  'user': ['query_movie_ids']},\n",
       " 'conf_path': 'D:/Python/notebook/restful/repo/user_supplied/movielens.local.yaml',\n",
       " 'count_': 100004,\n",
       " 'df_conf_':                                     id   m_dtype        date_format default  \\\n",
       " id                                                                            \n",
       " user_id                        user_id      catg               None    None   \n",
       " query_movie_ids        query_movie_ids      catg               None    None   \n",
       " genres                          genres      catg               None    None   \n",
       " avg_rating                  avg_rating      cont               None    None   \n",
       " year                              year      cont               None    None   \n",
       " candidate_movie_id  candidate_movie_id      catg               None    None   \n",
       " timestamp                    timestamp  datetime  %Y-%m-%d %H:%M:%S    None   \n",
       " rating                          rating      catg               None    None   \n",
       " \n",
       "                     is_multi   sep vocabs  \\\n",
       " id                                          \n",
       " user_id                False  None   None   \n",
       " query_movie_ids         True     ,   None   \n",
       " genres                  True     |   None   \n",
       " avg_rating             False  None   None   \n",
       " year                   False  None   None   \n",
       " candidate_movie_id     False  None   None   \n",
       " timestamp              False  None   None   \n",
       " rating                 False  None   None   \n",
       " \n",
       "                                                           vocabs_path    aux  \\\n",
       " id                                                                             \n",
       " user_id                                                          None  False   \n",
       " query_movie_ids     D:/Python/notebook/restful/repo/user_supplied/...  False   \n",
       " genres              D:/Python/notebook/restful/repo/user_supplied/...  False   \n",
       " avg_rating                                                       None  False   \n",
       " year                                                             None  False   \n",
       " candidate_movie_id  D:/Python/notebook/restful/repo/user_supplied/...  False   \n",
       " timestamp                                                        None  False   \n",
       " rating                                                           None  False   \n",
       " \n",
       "                      type                                          col_state  \n",
       " id                                                                            \n",
       " user_id              None                                               None  \n",
       " query_movie_ids      user  allow_null: true\\nclasses_: ['1', '2', '3', '4...  \n",
       " genres               item  allow_null: true\\nclasses_: [(no genres listed...  \n",
       " avg_rating           item  {cumsum_: 354374.99999999907, default: null, m...  \n",
       " year                 item  {cumsum_: 199176755.0, default: null, max_: 20...  \n",
       " candidate_movie_id   item  allow_null: true\\nclasses_: ['1', '2', '3', '4...  \n",
       " timestamp            None                                               None  \n",
       " rating              label  allow_null: false\\nclasses_: ['0', '1']\\ndefau...  ,\n",
       " 'raw_paths': ['D:/Python/notebook/restful/repo/user_supplied/raws/merged_movielens.csv'],\n",
       " 'tr_count_': 70182,\n",
       " 'vl_count_': 29822}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils = reload('recomm.trainer.utils.utils')\n",
    "env = reload('recomm.trainer.env')\n",
    "flex = reload('recomm.trainer.utils.flex')\n",
    "service = reload('recomm.trainer.service')\n",
    "\n",
    "ctrl = reload('recomm.trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml'}\n",
    "loader = ctrl.load_schema(params)\n",
    "\n",
    "vars(loader.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Cloud Ml-Engine Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cd D:\\Python\\notebook\\restful\\recomm &&             gcloud ml-engine jobs submit training foo_bar_movielens_recommendation_20180313104856810910                 --job-dir gs://recomm-job/foo-bar/movielens_recommendation/model                 --module-name trainer.ctrl                 --package-path trainer                 --region asia-east1                 --config config.yaml                 --runtime-version 1.4                 --                 --train-steps 1000                 --method train                 --conf-path gs://movielens-foo/user_supplied/movielens.yaml                 --job-id foo_bar_movielens_recommendation_20180313104856810910\n",
      "jobId: foo_bar_movielens_recommendation_20180313104856810910\n",
      "state: QUEUED\n",
      "D:\\Google\\Cloud SDK\\google-cloud-sdk\\lib\\googlecloudsdk\\core\\util\\files.py:622: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n",
      "  for chunk in iter(lambda: fp.read(4096), ''):\n",
      "Job [foo_bar_movielens_recommendation_20180313104856810910] submitted successfully.\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs describe foo_bar_movielens_recommendation_20180313104856810910\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ml-engine jobs stream-logs foo_bar_movielens_recommendation_20180313104856810910\n",
      "\n"
     ]
    }
   ],
   "source": [
    "utils = reload('recomm.trainer.utils.utils')\n",
    "env = reload('recomm.trainer.env')\n",
    "flex = reload('recomm.trainer.utils.flex')\n",
    "service = reload('recomm.trainer.service')\n",
    "\n",
    "ctrl = reload('recomm.trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml',\n",
    "          'runtime_version': '1.4'}\n",
    "ret = ctrl.train_submit(params)\n",
    "job_id = ret.get('job_id')\n",
    "print( ret.get('response') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Describe Job States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-13 10:49:29,258 - googleapiclient.discovery - INFO [line:274] - URL being requested: GET https://www.googleapis.com/discovery/v1/apis/ml/v1/rest\n",
      "2018-03-13 10:49:31,118 - googleapiclient.discovery - INFO [line:868] - URL being requested: GET https://ml.googleapis.com/v1/projects/training-recommendation-engine/jobs/foo_bar_movielens_recommendation_20180313104856810910?alt=json\n",
      "2018-03-13 10:49:31,119 - oauth2client.transport - INFO [line:151] - Attempting refresh to obtain initial access_token\n",
      "2018-03-13 10:49:31,153 - oauth2client.client - INFO [line:795] - Refreshing access_token\n",
      "2018-03-13 10:49:33,369 - Ctrl - INFO [line:207] - foo-bar: describe take time 0:00:04.298561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'createTime': '2018-03-13T02:49:02Z',\n",
       " 'jobId': 'foo_bar_movielens_recommendation_20180313104856810910',\n",
       " 'state': 'PREPARING',\n",
       " 'trainingInput': {'args': ['--train-steps',\n",
       "   '1000',\n",
       "   '--method',\n",
       "   'train',\n",
       "   '--conf-path',\n",
       "   'gs://movielens-foo/user_supplied/movielens.yaml',\n",
       "   '--job-id',\n",
       "   'foo_bar_movielens_recommendation_20180313104856810910'],\n",
       "  'jobDir': 'gs://recomm-job/foo-bar/movielens_recommendation/model',\n",
       "  'packageUris': ['gs://recomm-job/foo-bar/movielens_recommendation/model/packages/bf35e3c8bf0dc0b0dc14b04cc39463b2bd01a92fc664a452921911a2af66c201/trainer-0.1.tar.gz'],\n",
       "  'pythonModule': 'trainer.ctrl',\n",
       "  'pythonVersion': '3.5',\n",
       "  'region': 'asia-east1',\n",
       "  'runtimeVersion': '1.4'},\n",
       " 'trainingOutput': {}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "\n",
    "utils = reload('recomm.trainer.utils.utils')\n",
    "env = reload('recomm.trainer.env')\n",
    "flex = reload('recomm.trainer.utils.flex')\n",
    "service = reload('recomm.trainer.service')\n",
    "\n",
    "ctrl = reload('recomm.trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml', 'job_id': job_id}\n",
    "ctrl.describe(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "\n",
    "utils = reload('recomm.trainer.utils.utils')\n",
    "env = reload('recomm.trainer.env')\n",
    "flex = reload('recomm.trainer.utils.flex')\n",
    "service = reload('recomm.trainer.service')\n",
    "\n",
    "views = reload('recomm.views').ViewRecomm.instance\n",
    "params = {'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml'}\n",
    "ret = views.deploy(params)\n",
    "ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Information From Deployed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "\n",
    "utils = reload('recomm.trainer.utils.utils')\n",
    "env = reload('recomm.trainer.env')\n",
    "flex = reload('recomm.trainer.utils.flex')\n",
    "service = reload('recomm.trainer.service')\n",
    "\n",
    "views = reload('recomm.views').ViewRecomm.instance\n",
    "params = {'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml'}\n",
    "ret = views.model_info(params)\n",
    "ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restful predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-13 14:41:53,669 - Loader - INFO [line:360] - try to unserialize from D:\\Python\\notebook\\restful\\repo/foo-bar/movielens_recommendation/data/parsed.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>query_movie_ids</th>\n",
       "      <th>genres</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>year</th>\n",
       "      <th>candidate_movie_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1953,2105,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>4.260870</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>1172</td>\n",
       "      <td>2009-12-14 10:53:25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,2105,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>4.021739</td>\n",
       "      <td>1971.0</td>\n",
       "      <td>1953</td>\n",
       "      <td>2009-12-14 10:53:11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,31,1029,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "      <td>3.478723</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>2105</td>\n",
       "      <td>2009-12-14 10:52:19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,2105,1029,1061,1129,1263,1287,1293,1...</td>\n",
       "      <td>Drama</td>\n",
       "      <td>3.178571</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>31</td>\n",
       "      <td>2009-12-14 10:52:24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1172,1953,2105,31,1061,1129,1263,1287,1293,133...</td>\n",
       "      <td>Animation|Children|Drama|Musical</td>\n",
       "      <td>3.702381</td>\n",
       "      <td>1941.0</td>\n",
       "      <td>1029</td>\n",
       "      <td>2009-12-14 10:52:59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                    query_movie_ids  \\\n",
       "0        1  1953,2105,31,1029,1061,1129,1263,1287,1293,133...   \n",
       "1        1  1172,2105,31,1029,1061,1129,1263,1287,1293,133...   \n",
       "2        1  1172,1953,31,1029,1061,1129,1263,1287,1293,133...   \n",
       "3        1  1172,1953,2105,1029,1061,1129,1263,1287,1293,1...   \n",
       "4        1  1172,1953,2105,31,1061,1129,1263,1287,1293,133...   \n",
       "\n",
       "                             genres  avg_rating    year  candidate_movie_id  \\\n",
       "0                             Drama    4.260870  1989.0                1172   \n",
       "1             Action|Crime|Thriller    4.021739  1971.0                1953   \n",
       "2           Action|Adventure|Sci-Fi    3.478723  1982.0                2105   \n",
       "3                             Drama    3.178571  1995.0                  31   \n",
       "4  Animation|Children|Drama|Musical    3.702381  1941.0                1029   \n",
       "\n",
       "             timestamp  rating  \n",
       "0  2009-12-14 10:53:25       1  \n",
       "1  2009-12-14 10:53:11       1  \n",
       "2  2009-12-14 10:52:19       1  \n",
       "3  2009-12-14 10:52:24       0  \n",
       "4  2009-12-14 10:52:59       0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"{}/ml-latest-small/ratings.csv\".format(datapath))\n",
    "ratings['timestamp'] = ratings.timestamp.map(dt.datetime.fromtimestamp).map(str)\n",
    "ratings['ori_rating'] = ratings['rating']\n",
    "ratings['rating'] = (ratings.rating >= 4).astype(int)\n",
    "\n",
    "movies = pd.read_csv(\"{}/ml-latest-small/movies.csv\".format(datapath))\n",
    "avg_rt = ratings.groupby(\"movieId\", as_index=False).ori_rating.mean().rename(index=str, columns={'ori_rating': 'avg_rating'})\n",
    "movies = movies.merge(avg_rt, how='left', on='movieId')\n",
    "movies[\"year\"] = movies.title.str.findall(\"\\(\\s*(\\d+)\\s*\\)\").map(lambda lst: int(lst[-1]) if len(lst) else None)\n",
    "\n",
    "ctrl = reload('recomm.trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': 'D:/Python/notebook/restful/repo/user_supplied/movielens.local.yaml', 'is_local': True}\n",
    "loader = ctrl.load_schema(params)\n",
    "merged = pd.read_csv('D:/Python/notebook/restful/repo/user_supplied/raws/merged_movielens.csv', names=loader.schema.raw_cols)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>candidate_movie_id</th>\n",
       "      <th>genres</th>\n",
       "      <th>query_movie_ids</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.872470</td>\n",
       "      <td>1</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>32,1884,1580,1527,1387,1377,1376,1375,1372,135...</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.401869</td>\n",
       "      <td>2</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "      <td>32,1884,1580,1527,1387,1377,1376,1375,1372,135...</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.161017</td>\n",
       "      <td>3</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>32,1884,1580,1527,1387,1377,1376,1375,1372,135...</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.384615</td>\n",
       "      <td>4</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "      <td>32,1884,1580,1527,1387,1377,1376,1375,1372,135...</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.267857</td>\n",
       "      <td>5</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>32,1884,1580,1527,1387,1377,1376,1375,1372,135...</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.884615</td>\n",
       "      <td>6</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>32,1884,1580,1527,1387,1377,1376,1375,1372,135...</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.283019</td>\n",
       "      <td>7</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>32,1884,1580,1527,1387,1377,1376,1375,1372,135...</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.800000</td>\n",
       "      <td>8</td>\n",
       "      <td>Adventure|Children</td>\n",
       "      <td>32,1884,1580,1527,1387,1377,1376,1375,1372,135...</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.150000</td>\n",
       "      <td>9</td>\n",
       "      <td>Action</td>\n",
       "      <td>32,1884,1580,1527,1387,1377,1376,1375,1372,135...</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.450820</td>\n",
       "      <td>10</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "      <td>32,1884,1580,1527,1387,1377,1376,1375,1372,135...</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avg_rating candidate_movie_id                                       genres  \\\n",
       "0    3.872470                  1  Adventure|Animation|Children|Comedy|Fantasy   \n",
       "1    3.401869                  2                   Adventure|Children|Fantasy   \n",
       "2    3.161017                  3                               Comedy|Romance   \n",
       "3    2.384615                  4                         Comedy|Drama|Romance   \n",
       "4    3.267857                  5                                       Comedy   \n",
       "5    3.884615                  6                        Action|Crime|Thriller   \n",
       "6    3.283019                  7                               Comedy|Romance   \n",
       "7    3.800000                  8                           Adventure|Children   \n",
       "8    3.150000                  9                                       Action   \n",
       "9    3.450820                 10                    Action|Adventure|Thriller   \n",
       "\n",
       "                                     query_movie_ids    year  \n",
       "0  32,1884,1580,1527,1387,1377,1376,1375,1372,135...  1995.0  \n",
       "1  32,1884,1580,1527,1387,1377,1376,1375,1372,135...  1995.0  \n",
       "2  32,1884,1580,1527,1387,1377,1376,1375,1372,135...  1995.0  \n",
       "3  32,1884,1580,1527,1387,1377,1376,1375,1372,135...  1995.0  \n",
       "4  32,1884,1580,1527,1387,1377,1376,1375,1372,135...  1995.0  \n",
       "5  32,1884,1580,1527,1387,1377,1376,1375,1372,135...  1995.0  \n",
       "6  32,1884,1580,1527,1387,1377,1376,1375,1372,135...  1995.0  \n",
       "7  32,1884,1580,1527,1387,1377,1376,1375,1372,135...  1995.0  \n",
       "8  32,1884,1580,1527,1387,1377,1376,1375,1372,135...  1995.0  \n",
       "9  32,1884,1580,1527,1387,1377,1376,1375,1372,135...  1995.0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one user vs all items\n",
    "# def restful_data(user_ids, num=5):\n",
    "#     data = {\n",
    "#         'query_movie_ids': merged.query('user_id in {}'.format(user_ids)).groupby('user_id').query_movie_ids.max().tolist(),\n",
    "#     }\n",
    "#     items = movies.rename(index=str, columns={\"movieId\": \"candidate_movie_id\"}).drop('title', 1)\n",
    "#     items.loc[:, 'candidate_movie_id'] = items.candidate_movie_id.astype(str)\n",
    "#     # reduce to 5 records\n",
    "#     items = items[:num].to_dict('list')\n",
    "#     data.update(items)\n",
    "#     return data\n",
    "def restful_data(user_ids, num=10):\n",
    "    query_movie_ids = merged.query('user_id in {}'.format(user_ids))\\\n",
    "                            .groupby('user_id')\\\n",
    "                            .query_movie_ids.max()\\\n",
    "                            .tolist()\n",
    "    items = movies.rename(index=str, columns={\"movieId\": \"candidate_movie_id\"}).drop('title', 1)\n",
    "    items.loc[:, 'candidate_movie_id'] = items.candidate_movie_id.astype(str)\n",
    "    items.loc[:, 'query_movie_ids'] = query_movie_ids[0]\n",
    "    # reduce to 5 records\n",
    "    items = items[:num].to_dict('records')\n",
    "    return items\n",
    "\n",
    "pd.DataFrame(restful_data((22,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restful Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'avg_rating': 3.4508196721311477,\n",
       "  'candidate_movie_id': '10',\n",
       "  'genres': 'Action|Adventure|Thriller',\n",
       "  'query_movie_ids': '32,1884,1580,1527,1387,1377,1376,1375,1372,1356,1339,1291,1270,1255,1240,1215,1210,1200,2174,2288,2291,3081,4011,3868,3793,3535,3527,3355,3213,3033,2459,2987,2959,2858,2762,2712,2571,2542,1198,1799,457,648,555,480,551,589,541,592,593,253,260,163,296,858,1089,2881,235,2990,2953,231,3052,208,2985,1148,2763,3147,267,2723,2717,2716,2710,2701,2700,2683,2672,3082,3300,3176,3751,4015,47,3999,3996,3994,3977,48,3826,3809,70,3697,173,3623,3578,153,158,3438,3408,3354,2617,3285,3253,2657,356,2616,588,1693,1682,1645,1641,1625,1608,1544,1391,552,586,1374,2605,1371,1320,784,1263,785,1080,1214,1208,1201,1097,1721,1722,1769,44,315,355,2502,1101,2431,2402,2340,2301,442,2232,2115,2081,2023,2011,2006,1997,1923,1917,1909,485,1876,4027',\n",
       "  'year': 1995.0},\n",
       " {'avg_rating': 3.15,\n",
       "  'candidate_movie_id': '9',\n",
       "  'genres': 'Action',\n",
       "  'query_movie_ids': '32,1884,1580,1527,1387,1377,1376,1375,1372,1356,1339,1291,1270,1255,1240,1215,1210,1200,2174,2288,2291,3081,4011,3868,3793,3535,3527,3355,3213,3033,2459,2987,2959,2858,2762,2712,2571,2542,1198,1799,457,648,555,480,551,589,541,592,593,253,260,163,296,858,1089,2881,235,2990,2953,231,3052,208,2985,1148,2763,3147,267,2723,2717,2716,2710,2701,2700,2683,2672,3082,3300,3176,3751,4015,47,3999,3996,3994,3977,48,3826,3809,70,3697,173,3623,3578,153,158,3438,3408,3354,2617,3285,3253,2657,356,2616,588,1693,1682,1645,1641,1625,1608,1544,1391,552,586,1374,2605,1371,1320,784,1263,785,1080,1214,1208,1201,1097,1721,1722,1769,44,315,355,2502,1101,2431,2402,2340,2301,442,2232,2115,2081,2023,2011,2006,1997,1923,1917,1909,485,1876,4027',\n",
       "  'year': 1995.0},\n",
       " {'avg_rating': 3.8,\n",
       "  'candidate_movie_id': '8',\n",
       "  'genres': 'Adventure|Children',\n",
       "  'query_movie_ids': '32,1884,1580,1527,1387,1377,1376,1375,1372,1356,1339,1291,1270,1255,1240,1215,1210,1200,2174,2288,2291,3081,4011,3868,3793,3535,3527,3355,3213,3033,2459,2987,2959,2858,2762,2712,2571,2542,1198,1799,457,648,555,480,551,589,541,592,593,253,260,163,296,858,1089,2881,235,2990,2953,231,3052,208,2985,1148,2763,3147,267,2723,2717,2716,2710,2701,2700,2683,2672,3082,3300,3176,3751,4015,47,3999,3996,3994,3977,48,3826,3809,70,3697,173,3623,3578,153,158,3438,3408,3354,2617,3285,3253,2657,356,2616,588,1693,1682,1645,1641,1625,1608,1544,1391,552,586,1374,2605,1371,1320,784,1263,785,1080,1214,1208,1201,1097,1721,1722,1769,44,315,355,2502,1101,2431,2402,2340,2301,442,2232,2115,2081,2023,2011,2006,1997,1923,1917,1909,485,1876,4027',\n",
       "  'year': 1995.0},\n",
       " {'avg_rating': 3.2830188679245285,\n",
       "  'candidate_movie_id': '7',\n",
       "  'genres': 'Comedy|Romance',\n",
       "  'query_movie_ids': '32,1884,1580,1527,1387,1377,1376,1375,1372,1356,1339,1291,1270,1255,1240,1215,1210,1200,2174,2288,2291,3081,4011,3868,3793,3535,3527,3355,3213,3033,2459,2987,2959,2858,2762,2712,2571,2542,1198,1799,457,648,555,480,551,589,541,592,593,253,260,163,296,858,1089,2881,235,2990,2953,231,3052,208,2985,1148,2763,3147,267,2723,2717,2716,2710,2701,2700,2683,2672,3082,3300,3176,3751,4015,47,3999,3996,3994,3977,48,3826,3809,70,3697,173,3623,3578,153,158,3438,3408,3354,2617,3285,3253,2657,356,2616,588,1693,1682,1645,1641,1625,1608,1544,1391,552,586,1374,2605,1371,1320,784,1263,785,1080,1214,1208,1201,1097,1721,1722,1769,44,315,355,2502,1101,2431,2402,2340,2301,442,2232,2115,2081,2023,2011,2006,1997,1923,1917,1909,485,1876,4027',\n",
       "  'year': 1995.0},\n",
       " {'avg_rating': 3.8846153846153846,\n",
       "  'candidate_movie_id': '6',\n",
       "  'genres': 'Action|Crime|Thriller',\n",
       "  'query_movie_ids': '32,1884,1580,1527,1387,1377,1376,1375,1372,1356,1339,1291,1270,1255,1240,1215,1210,1200,2174,2288,2291,3081,4011,3868,3793,3535,3527,3355,3213,3033,2459,2987,2959,2858,2762,2712,2571,2542,1198,1799,457,648,555,480,551,589,541,592,593,253,260,163,296,858,1089,2881,235,2990,2953,231,3052,208,2985,1148,2763,3147,267,2723,2717,2716,2710,2701,2700,2683,2672,3082,3300,3176,3751,4015,47,3999,3996,3994,3977,48,3826,3809,70,3697,173,3623,3578,153,158,3438,3408,3354,2617,3285,3253,2657,356,2616,588,1693,1682,1645,1641,1625,1608,1544,1391,552,586,1374,2605,1371,1320,784,1263,785,1080,1214,1208,1201,1097,1721,1722,1769,44,315,355,2502,1101,2431,2402,2340,2301,442,2232,2115,2081,2023,2011,2006,1997,1923,1917,1909,485,1876,4027',\n",
       "  'year': 1995.0},\n",
       " {'avg_rating': 3.267857142857143,\n",
       "  'candidate_movie_id': '5',\n",
       "  'genres': 'Comedy',\n",
       "  'query_movie_ids': '32,1884,1580,1527,1387,1377,1376,1375,1372,1356,1339,1291,1270,1255,1240,1215,1210,1200,2174,2288,2291,3081,4011,3868,3793,3535,3527,3355,3213,3033,2459,2987,2959,2858,2762,2712,2571,2542,1198,1799,457,648,555,480,551,589,541,592,593,253,260,163,296,858,1089,2881,235,2990,2953,231,3052,208,2985,1148,2763,3147,267,2723,2717,2716,2710,2701,2700,2683,2672,3082,3300,3176,3751,4015,47,3999,3996,3994,3977,48,3826,3809,70,3697,173,3623,3578,153,158,3438,3408,3354,2617,3285,3253,2657,356,2616,588,1693,1682,1645,1641,1625,1608,1544,1391,552,586,1374,2605,1371,1320,784,1263,785,1080,1214,1208,1201,1097,1721,1722,1769,44,315,355,2502,1101,2431,2402,2340,2301,442,2232,2115,2081,2023,2011,2006,1997,1923,1917,1909,485,1876,4027',\n",
       "  'year': 1995.0},\n",
       " {'avg_rating': 2.3846153846153846,\n",
       "  'candidate_movie_id': '4',\n",
       "  'genres': 'Comedy|Drama|Romance',\n",
       "  'query_movie_ids': '32,1884,1580,1527,1387,1377,1376,1375,1372,1356,1339,1291,1270,1255,1240,1215,1210,1200,2174,2288,2291,3081,4011,3868,3793,3535,3527,3355,3213,3033,2459,2987,2959,2858,2762,2712,2571,2542,1198,1799,457,648,555,480,551,589,541,592,593,253,260,163,296,858,1089,2881,235,2990,2953,231,3052,208,2985,1148,2763,3147,267,2723,2717,2716,2710,2701,2700,2683,2672,3082,3300,3176,3751,4015,47,3999,3996,3994,3977,48,3826,3809,70,3697,173,3623,3578,153,158,3438,3408,3354,2617,3285,3253,2657,356,2616,588,1693,1682,1645,1641,1625,1608,1544,1391,552,586,1374,2605,1371,1320,784,1263,785,1080,1214,1208,1201,1097,1721,1722,1769,44,315,355,2502,1101,2431,2402,2340,2301,442,2232,2115,2081,2023,2011,2006,1997,1923,1917,1909,485,1876,4027',\n",
       "  'year': 1995.0},\n",
       " {'avg_rating': 3.1610169491525424,\n",
       "  'candidate_movie_id': '3',\n",
       "  'genres': 'Comedy|Romance',\n",
       "  'query_movie_ids': '32,1884,1580,1527,1387,1377,1376,1375,1372,1356,1339,1291,1270,1255,1240,1215,1210,1200,2174,2288,2291,3081,4011,3868,3793,3535,3527,3355,3213,3033,2459,2987,2959,2858,2762,2712,2571,2542,1198,1799,457,648,555,480,551,589,541,592,593,253,260,163,296,858,1089,2881,235,2990,2953,231,3052,208,2985,1148,2763,3147,267,2723,2717,2716,2710,2701,2700,2683,2672,3082,3300,3176,3751,4015,47,3999,3996,3994,3977,48,3826,3809,70,3697,173,3623,3578,153,158,3438,3408,3354,2617,3285,3253,2657,356,2616,588,1693,1682,1645,1641,1625,1608,1544,1391,552,586,1374,2605,1371,1320,784,1263,785,1080,1214,1208,1201,1097,1721,1722,1769,44,315,355,2502,1101,2431,2402,2340,2301,442,2232,2115,2081,2023,2011,2006,1997,1923,1917,1909,485,1876,4027',\n",
       "  'year': 1995.0},\n",
       " {'avg_rating': 3.4018691588785046,\n",
       "  'candidate_movie_id': '2',\n",
       "  'genres': 'Adventure|Children|Fantasy',\n",
       "  'query_movie_ids': '32,1884,1580,1527,1387,1377,1376,1375,1372,1356,1339,1291,1270,1255,1240,1215,1210,1200,2174,2288,2291,3081,4011,3868,3793,3535,3527,3355,3213,3033,2459,2987,2959,2858,2762,2712,2571,2542,1198,1799,457,648,555,480,551,589,541,592,593,253,260,163,296,858,1089,2881,235,2990,2953,231,3052,208,2985,1148,2763,3147,267,2723,2717,2716,2710,2701,2700,2683,2672,3082,3300,3176,3751,4015,47,3999,3996,3994,3977,48,3826,3809,70,3697,173,3623,3578,153,158,3438,3408,3354,2617,3285,3253,2657,356,2616,588,1693,1682,1645,1641,1625,1608,1544,1391,552,586,1374,2605,1371,1320,784,1263,785,1080,1214,1208,1201,1097,1721,1722,1769,44,315,355,2502,1101,2431,2402,2340,2301,442,2232,2115,2081,2023,2011,2006,1997,1923,1917,1909,485,1876,4027',\n",
       "  'year': 1995.0},\n",
       " {'avg_rating': 3.8724696356275303,\n",
       "  'candidate_movie_id': '1',\n",
       "  'genres': 'Adventure|Animation|Children|Comedy|Fantasy',\n",
       "  'query_movie_ids': '32,1884,1580,1527,1387,1377,1376,1375,1372,1356,1339,1291,1270,1255,1240,1215,1210,1200,2174,2288,2291,3081,4011,3868,3793,3535,3527,3355,3213,3033,2459,2987,2959,2858,2762,2712,2571,2542,1198,1799,457,648,555,480,551,589,541,592,593,253,260,163,296,858,1089,2881,235,2990,2953,231,3052,208,2985,1148,2763,3147,267,2723,2717,2716,2710,2701,2700,2683,2672,3082,3300,3176,3751,4015,47,3999,3996,3994,3977,48,3826,3809,70,3697,173,3623,3578,153,158,3438,3408,3354,2617,3285,3253,2657,356,2616,588,1693,1682,1645,1641,1625,1608,1544,1391,552,586,1374,2605,1371,1320,784,1263,785,1080,1214,1208,1201,1097,1721,1722,1769,44,315,355,2502,1101,2431,2402,2340,2301,442,2232,2115,2081,2023,2011,2006,1997,1923,1917,1909,485,1876,4027',\n",
       "  'year': 1995.0}]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = restful_data((22,))\n",
    "inputs.reverse()\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'err_cde': '00',\n",
       " 'response': [0.3389380872249603,\n",
       "  0.49546846747398376,\n",
       "  0.29588234424591064,\n",
       "  0.471061110496521,\n",
       "  0.18395668268203735,\n",
       "  0.4615522027015686,\n",
       "  0.8539339900016785,\n",
       "  0.5304296612739563,\n",
       "  0.36504778265953064,\n",
       "  0.21630224585533142]}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "# job_id = 'foo_bar_movielens_recommendation_20180313142623533104'\n",
    "inputs = restful_data((22,))\n",
    "inputs.reverse()\n",
    "resp = requests.post(\n",
    "    'http://127.0.0.1:8000/api/recomm/online_predict/',\n",
    "    data={'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml',\n",
    "          'json_data': json.dumps(inputs)}\n",
    ")\n",
    "r = json.loads(resp.text)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utils = reload('recomm.trainer.utils.utils')\n",
    "env = reload('recomm.trainer.env')\n",
    "flex = reload('recomm.trainer.utils.flex')\n",
    "service = reload('recomm.trainer.service')\n",
    "\n",
    "views = reload('recomm.views').ViewRecomm.instance\n",
    "params = {'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml',\n",
    "          'json_data': restful_data((22,))}\n",
    "ret = views.predict(params)\n",
    "ret.get('response')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import predictor\n",
    "\n",
    "utils = reload('recomm.trainer.utils.utils')\n",
    "env = reload('recomm.trainer.env')\n",
    "flex = reload('recomm.trainer.utils.flex')\n",
    "reload('recomm.trainer.reco_mf_dnn_est')\n",
    "service = reload('recomm.trainer.service')\n",
    "\n",
    "data = restful_data((22,))\n",
    "views = reload('recomm.views').ViewRecomm.instance\n",
    "params = {'conf_path': '../data/foo/user_supplied/movielens.local.yaml', 'is_local': True, 'json_data': data}\n",
    "data_for_model = views.transform(params).get('response')\n",
    "\n",
    "del data_for_model['query_movie_ids']\n",
    "pred_fn = predictor.from_saved_model('../repo/foo-bar/movielens_recommendation/model/export/export_foo-bar/1520581839')\n",
    "pred_fn(data_for_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.saved_model.loader.load(sess, \n",
    "        [tf.saved_model.tag_constants.SERVING],\n",
    "        export_dir='../repo/foo-bar/movielens_recommendation/model/export/export_foo-bar/1520581839')\n",
    "    for n in sess.graph.as_graph_def().node:\n",
    "        print(n.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = result.get('response')\n",
    "# vars(model)\n",
    "utils = reload('recomm.trainer.utils.utils')\n",
    "env = reload('recomm.trainer.env')\n",
    "flex = reload('recomm.trainer.utils.flex')\n",
    "service = reload('recomm.trainer.service')\n",
    "\n",
    "ctrl = reload('recomm.trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': '../data/foo/user_supplied/movielens.local.yaml', \n",
    "          'is_local': True,\n",
    "          'runtime_version': '1.4',\n",
    "          'train_steps': 600}\n",
    "\n",
    "tf.reset_default_graph()\n",
    "model, p = ctrl.get_model(params)\n",
    "train_input = model.input_fn2([p.train_file], n_epoch=1, n_batch=5)\n",
    "features, labels = train_input()\n",
    "print('\\nfeatures: ', features)\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print( sess.run(features) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Local Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-13 11:23:05,663 - Loader - INFO [line:368] - try to parse D:/Python/notebook/restful/repo/user_supplied/movielens.local.yaml (user supplied) ...\n",
      "2018-03-13 11:23:06,102 - CatgMapper - INFO [line:319] - [query_movie_ids] fetch vocab [D:/Python/notebook/restful/repo/user_supplied/item.vocab] \n",
      "2018-03-13 11:23:06,111 - CatgMapper - INFO [line:319] - [genres] fetch vocab [D:/Python/notebook/restful/repo/user_supplied/genres.vocab] \n",
      "2018-03-13 11:23:06,132 - CatgMapper - INFO [line:319] - [candidate_movie_id] fetch vocab [D:/Python/notebook/restful/repo/user_supplied/item.vocab] \n",
      "2018-03-13 11:23:08,506 - Loader - INFO [line:381] - try to transform ['D:/Python/notebook/restful/repo/user_supplied/raws/merged_movielens.csv'] ... \n",
      "2018-03-13 11:23:54,164 - Loader - INFO [line:440] - [D:/Python/notebook/restful/repo/user_supplied/raws/merged_movielens.csv]: process take time 0:00:44.931433\n"
     ]
    }
   ],
   "source": [
    "utils = reload('recomm.trainer.utils.utils')\n",
    "env = reload('recomm.trainer.env')\n",
    "flex = reload('recomm.trainer.utils.flex')\n",
    "service = reload('recomm.trainer.service')\n",
    "\n",
    "ctrl = reload('recomm.trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': 'D:/Python/notebook/restful/repo/user_supplied/movielens.local.yaml', 'is_local': True}\n",
    "ctrl.gen_data(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Local View Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'col_states_': OrderedDict([('query_movie_ids',\n",
       "               CatgMapper(allow_null=True, default=None, is_multi=True,\n",
       "                     name='query_movie_ids', sep=',', vocabs=None, vocabs_path=None)),\n",
       "              ('genres',\n",
       "               CatgMapper(allow_null=True, default=None, is_multi=True, name='genres',\n",
       "                     sep='|', vocabs=None, vocabs_path=None)),\n",
       "              ('avg_rating', NumericMapper(default=None, name='avg_rating')),\n",
       "              ('year', NumericMapper(default=None, name='year')),\n",
       "              ('candidate_movie_id',\n",
       "               CatgMapper(allow_null=True, default=None, is_multi=False,\n",
       "                     name='candidate_movie_id', sep=None, vocabs=None, vocabs_path=None)),\n",
       "              ('rating',\n",
       "               CatgMapper(allow_null=False, default=None, is_multi=False, name='rating',\n",
       "                     sep=None, vocabs=None, vocabs_path=None))]),\n",
       " 'conf_': {'columns': [{'id': 'user_id', 'm_dtype': 'catg'},\n",
       "   {'id': 'query_movie_ids',\n",
       "    'is_multi': True,\n",
       "    'm_dtype': 'catg',\n",
       "    'sep': ',',\n",
       "    'vocabs_path': 'D:/Python/notebook/restful/repo/user_supplied/item.vocab'},\n",
       "   {'id': 'genres',\n",
       "    'is_multi': True,\n",
       "    'm_dtype': 'catg',\n",
       "    'sep': '|',\n",
       "    'vocabs_path': 'D:/Python/notebook/restful/repo/user_supplied/genres.vocab'},\n",
       "   {'id': 'avg_rating', 'm_dtype': 'cont'},\n",
       "   {'id': 'year', 'm_dtype': 'cont'},\n",
       "   {'id': 'candidate_movie_id',\n",
       "    'm_dtype': 'catg',\n",
       "    'vocabs_path': 'D:/Python/notebook/restful/repo/user_supplied/item.vocab'},\n",
       "   {'date_format': '%Y-%m-%d %H:%M:%S',\n",
       "    'id': 'timestamp',\n",
       "    'm_dtype': 'datetime'},\n",
       "   {'id': 'rating', 'm_dtype': 'catg'}],\n",
       "  'item': ['genres', 'avg_rating', 'year', 'candidate_movie_id'],\n",
       "  'label': ['rating'],\n",
       "  'model_id': 'movielens_recommendation',\n",
       "  'project_id': 'foo-bar',\n",
       "  'raw_dir': 'D:/Python/notebook/restful/repo/user_supplied/raws',\n",
       "  'user': ['query_movie_ids']},\n",
       " 'conf_path': 'D:/Python/notebook/restful/repo/user_supplied/movielens.local.yaml',\n",
       " 'count_': 100004,\n",
       " 'df_conf_':                                     id   m_dtype        date_format default  \\\n",
       " id                                                                            \n",
       " user_id                        user_id      catg               None    None   \n",
       " query_movie_ids        query_movie_ids      catg               None    None   \n",
       " genres                          genres      catg               None    None   \n",
       " avg_rating                  avg_rating      cont               None    None   \n",
       " year                              year      cont               None    None   \n",
       " candidate_movie_id  candidate_movie_id      catg               None    None   \n",
       " timestamp                    timestamp  datetime  %Y-%m-%d %H:%M:%S    None   \n",
       " rating                          rating      catg               None    None   \n",
       " \n",
       "                     is_multi   sep vocabs  \\\n",
       " id                                          \n",
       " user_id                False  None   None   \n",
       " query_movie_ids         True     ,   None   \n",
       " genres                  True     |   None   \n",
       " avg_rating             False  None   None   \n",
       " year                   False  None   None   \n",
       " candidate_movie_id     False  None   None   \n",
       " timestamp              False  None   None   \n",
       " rating                 False  None   None   \n",
       " \n",
       "                                                           vocabs_path    aux  \\\n",
       " id                                                                             \n",
       " user_id                                                          None  False   \n",
       " query_movie_ids     D:/Python/notebook/restful/repo/user_supplied/...  False   \n",
       " genres              D:/Python/notebook/restful/repo/user_supplied/...  False   \n",
       " avg_rating                                                       None  False   \n",
       " year                                                             None  False   \n",
       " candidate_movie_id  D:/Python/notebook/restful/repo/user_supplied/...  False   \n",
       " timestamp                                                        None  False   \n",
       " rating                                                           None  False   \n",
       " \n",
       "                      type                                          col_state  \n",
       " id                                                                            \n",
       " user_id              None                                               None  \n",
       " query_movie_ids      user  allow_null: true\\nclasses_: ['1', '2', '3', '4...  \n",
       " genres               item  allow_null: true\\nclasses_: [(no genres listed...  \n",
       " avg_rating           item  {cumsum_: 354374.99999999907, default: null, m...  \n",
       " year                 item  {cumsum_: 199176755.0, default: null, max_: 20...  \n",
       " candidate_movie_id   item  allow_null: true\\nclasses_: ['1', '2', '3', '4...  \n",
       " timestamp            None                                               None  \n",
       " rating              label  allow_null: false\\nclasses_: ['0', '1']\\ndefau...  ,\n",
       " 'raw_paths': ['D:/Python/notebook/restful/repo/user_supplied/raws/merged_movielens.csv'],\n",
       " 'tr_count_': 70182,\n",
       " 'vl_count_': 29822}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils = reload('recomm.trainer.utils.utils')\n",
    "env = reload('recomm.trainer.env')\n",
    "flex = reload('recomm.trainer.utils.flex')\n",
    "service = reload('recomm.trainer.service')\n",
    "\n",
    "with flex.io('D:/Python/notebook/restful/repo/foo-bar/movielens_recommendation/data/parsed.yaml').as_reader() as f:\n",
    "    schema = flex.Schema.unserialize(f.stream)\n",
    "vars(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Local Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-13 17:52:58,932 - Ctrl - INFO [line:87] - received params: {'train_steps': 600, 'is_local': True, 'runtime_version': '1.4', 'conf_path': 'D:/Python/notebook/restful/repo/user_supplied/movielens.local.yaml'}\n",
      "2018-03-13 17:52:58,935 - Ctrl - INFO [line:93] - do local training\n",
      "2018-03-13 17:52:58,960 - Ctrl - INFO [line:113] - foo-bar: try to unserialize D:\\Python\\notebook\\restful\\repo/foo-bar/movielens_recommendation/data/parsed.yaml\n",
      "2018-03-13 17:53:00,499 - Service - INFO [line:48] - received params: {'deploy_path': 'D:\\\\Python\\\\notebook\\\\restful\\\\repo/foo-bar/movielens_recommendation/data/deploy.yaml', 'train_steps': 600, 'parsed_conf_path': 'D:\\\\Python\\\\notebook\\\\restful\\\\repo/foo-bar/movielens_recommendation/data/parsed.yaml', 'eval_name': 'foo-bar', 'raw_dir': 'D:/Python/notebook/restful/repo/user_supplied/raws', 'data_dir': 'D:\\\\Python\\\\notebook\\\\restful\\\\repo/foo-bar/movielens_recommendation/data', 'model_id': 'movielens_recommendation', 'save_every_steps': None, 'train_file': 'D:\\\\Python\\\\notebook\\\\restful\\\\repo/foo-bar/movielens_recommendation/data/data.tr', 'job_id': 'foo_bar_movielens_recommendation_20180313175300498967', 'job_dir': 'D:\\\\Python\\\\notebook\\\\restful\\\\repo/foo-bar/movielens_recommendation/model', 'n_batch': 128, 'is_local': True, 'valid_file': 'D:\\\\Python\\\\notebook\\\\restful\\\\repo/foo-bar/movielens_recommendation/data/data.vl', 'repo': 'D:\\\\Python\\\\notebook\\\\restful\\\\repo/foo-bar/movielens_recommendation', 'runtime_version': '1.4', 'conf_path': 'D:/Python/notebook/restful/repo/user_supplied/movielens.local.yaml', 'eval_steps': 233, 'dim': 16, 'export_name': 'export_foo-bar', 'pid': 'foo-bar'}\n",
      "2018-03-13 17:53:00,517 - BestScoreExporter - INFO [line:401] - BestScoreExporter init\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'D:\\\\Python\\\\notebook\\\\restful\\\\repo/foo-bar/movielens_recommendation/model', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000023C129B5780>, '_save_checkpoints_steps': None, '_task_type': 'worker', '_keep_checkpoint_max': 5, '_log_step_count_steps': 300, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': 88, '_master': '', '_is_chief': True, '_save_checkpoints_secs': 600, '_evaluation_master': '', '_task_id': 0, '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_global_id_in_cluster': 0, '_service': None, '_save_summary_steps': 100}\n",
      "2018-03-13 17:53:00,523 - tensorflow - INFO [line:116] - Using config: {'_model_dir': 'D:\\\\Python\\\\notebook\\\\restful\\\\repo/foo-bar/movielens_recommendation/model', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000023C129B5780>, '_save_checkpoints_steps': None, '_task_type': 'worker', '_keep_checkpoint_max': 5, '_log_step_count_steps': 300, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': 88, '_master': '', '_is_chief': True, '_save_checkpoints_secs': 600, '_evaluation_master': '', '_task_id': 0, '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_global_id_in_cluster': 0, '_service': None, '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "2018-03-13 17:53:00,527 - tensorflow - INFO [line:116] - Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "2018-03-13 17:53:00,530 - tensorflow - INFO [line:116] - Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "2018-03-13 17:53:00,616 - Ctrl - ERROR [line:136] - The two structures don't have the same sequence length. Input structure has length 6, while shallow structure has length 8.\n",
      "Traceback (most recent call last):\n",
      "  File \"D:/Python/notebook/restful\\recomm\\trainer\\ctrl.py\", line 134, in train\n",
      "    return self.service.train(p, schema)\n",
      "  File \"D:/Python/notebook/restful\\recomm\\trainer\\service.py\", line 58, in train\n",
      "    model.fit(train_input, valid_input, reset=True)\n",
      "  File \"D:/Python/notebook/restful\\recomm\\trainer\\reco_mf_dnn_est.py\", line 368, in fit\n",
      "    tf.estimator.train_and_evaluate(self.estimator_, train_spec, eval_spec)\n",
      "  File \"D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 421, in train_and_evaluate\n",
      "    executor.run()\n",
      "  File \"D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 494, in run\n",
      "    self.run_local()\n",
      "  File \"D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 626, in run_local\n",
      "    hooks=train_hooks)\n",
      "  File \"D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 352, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 809, in _train_model\n",
      "    input_fn, model_fn_lib.ModeKeys.TRAIN))\n",
      "  File \"D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 668, in _get_features_and_labels_from_input_fn\n",
      "    result = self._call_input_fn(input_fn, mode)\n",
      "  File \"D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 760, in _call_input_fn\n",
      "    return input_fn(**kwargs)\n",
      "  File \"D:/Python/notebook/restful\\recomm\\trainer\\reco_mf_dnn_est.py\", line 275, in _input_fn\n",
      "    OrderedDict(zip(cols, tuple([None] if e else [] for e in has_multi))))\n",
      "  File \"D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 773, in padded_batch\n",
      "    return PaddedBatchDataset(self, batch_size, padded_shapes, padding_values)\n",
      "  File \"D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1492, in __init__\n",
      "    input_dataset.output_shapes, _partial_shape_to_tensor, padded_shapes)\n",
      "  File \"D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\", line 531, in map_structure_up_to\n",
      "    assert_shallow_structure(shallow_tree, input_tree)\n",
      "  File \"D:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\", line 377, in assert_shallow_structure\n",
      "    % (len(input_tree), len(shallow_tree)))\n",
      "ValueError: The two structures don't have the same sequence length. Input structure has length 6, while shallow structure has length 8.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The two structures don't have the same sequence length. Input structure has length 6, while shallow structure has length 8.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-d869a4b6b948>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m           \u001b[1;34m'runtime_version'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'1.4'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m           'train_steps': 600}\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:/Python/notebook/restful\\recomm\\trainer\\ctrl.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    135\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:/Python/notebook/restful\\recomm\\trainer\\ctrl.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'job_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_job_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mservice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:/Python/notebook/restful\\recomm\\trainer\\service.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, p, schema)\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[1;31m# os.makedirs(utils.join(p.job_dir, 'export', p.export_name))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# export deploy info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:/Python/notebook/restful\\recomm\\trainer\\reco_mf_dnn_est.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_input, valid_input, reset)\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;31m# self.estimator_ = tf.estimator.Estimator(model_fn=self.graphing, model_dir=self.model_dir, config=run_config)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_est\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 368\u001b[1;33m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    369\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[0;32m    419\u001b[0m         '(with task id 0).  Given task id {}'.format(config.task_id))\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m   \u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    492\u001b[0m         config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[0;32m    493\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m       \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\u001b[0m in \u001b[0;36mrun_local\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    624\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m           \u001b[0mmax_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m           hooks=train_hooks)\n\u001b[0m\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m       \u001b[1;31m# Final export signal: For any eval result with global_step >= train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m    807\u001b[0m       features, labels, input_hooks = (\n\u001b[0;32m    808\u001b[0m           self._get_features_and_labels_from_input_fn(\n\u001b[1;32m--> 809\u001b[1;33m               input_fn, model_fn_lib.ModeKeys.TRAIN))\n\u001b[0m\u001b[0;32m    810\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m       estimator_spec = self._call_model_fn(\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_get_features_and_labels_from_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m    666\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_features_and_labels_from_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m     \u001b[1;34m\"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m     \u001b[0minput_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m    758\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/cpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:/Python/notebook/restful\\recomm\\trainer\\reco_mf_dnn_est.py\u001b[0m in \u001b[0;36m_input_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    273\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhas_multi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m                 dataset = dataset.padded_batch(n_batch,\n\u001b[1;32m--> 275\u001b[1;33m                             OrderedDict(zip(cols, tuple([None] if e else [] for e in has_multi))))\n\u001b[0m\u001b[0;32m    276\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m                 \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mpadded_batch\u001b[1;34m(self, batch_size, padded_shapes, padding_values)\u001b[0m\n\u001b[0;32m    771\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m     \"\"\"\n\u001b[1;32m--> 773\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mPaddedBatchDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadded_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, batch_size, padded_shapes, padding_values)\u001b[0m\n\u001b[0;32m   1490\u001b[0m         if padding_values is not None else _default_padding(input_dataset))\n\u001b[0;32m   1491\u001b[0m     self._padded_shapes = nest.map_structure_up_to(\n\u001b[1;32m-> 1492\u001b[1;33m         input_dataset.output_shapes, _partial_shape_to_tensor, padded_shapes)\n\u001b[0m\u001b[0;32m   1493\u001b[0m     self._padding_values = nest.map_structure_up_to(\n\u001b[0;32m   1494\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_padding_value_to_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure_up_to\u001b[1;34m(shallow_tree, func, *inputs)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot map over no sequences\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0minput_tree\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m     \u001b[0massert_shallow_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshallow_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m   \u001b[1;31m# Flatten each input separately, apply the function to corresponding elements,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\u001b[0m in \u001b[0;36massert_shallow_structure\u001b[1;34m(shallow_tree, input_tree, check_types)\u001b[0m\n\u001b[0;32m    375\u001b[0m           \u001b[1;34m\"The two structures don't have the same sequence length. Input \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m           \u001b[1;34m\"structure has length %s, while shallow structure has length %s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m           % (len(input_tree), len(shallow_tree)))\n\u001b[0m\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheck_types\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshallow_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The two structures don't have the same sequence length. Input structure has length 6, while shallow structure has length 8."
     ]
    }
   ],
   "source": [
    "utils = reload('recomm.trainer.utils.utils')\n",
    "env = reload('recomm.trainer.env')\n",
    "est = reload('recomm.trainer.reco_mf_dnn_est')\n",
    "flex = reload('recomm.trainer.utils.flex')\n",
    "service = reload('recomm.trainer.service')\n",
    "\n",
    "ctrl = reload('recomm.trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': 'D:/Python/notebook/restful/repo/user_supplied/movielens.local.yaml', \n",
    "          'is_local': True,\n",
    "          'runtime_version': '1.4',\n",
    "          'train_steps': 600}\n",
    "result = ctrl.train(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Get Model and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_master': '', '_global_id_in_cluster': 0, '_service': None, '_task_id': 0, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_is_chief': True, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_session_config': None, '_model_dir': 'D:\\\\Python\\\\notebook\\\\restful\\\\repo/foo-bar/movielens_recommendation/model', '_save_summary_steps': 100, '_log_step_count_steps': 300, '_tf_random_seed': 88, '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_save_checkpoints_steps': None, '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000028580401C18>}\n",
      "2018-03-13 10:41:28,131 - tensorflow - INFO [line:116] - Using config: {'_master': '', '_global_id_in_cluster': 0, '_service': None, '_task_id': 0, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_is_chief': True, '_save_checkpoints_secs': 600, '_keep_checkpoint_max': 5, '_session_config': None, '_model_dir': 'D:\\\\Python\\\\notebook\\\\restful\\\\repo/foo-bar/movielens_recommendation/model', '_save_summary_steps': 100, '_log_step_count_steps': 300, '_tf_random_seed': 88, '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_save_checkpoints_steps': None, '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000028580401C18>}\n",
      "2018-03-13 10:41:28,133 - Loader - INFO [line:363] - try to unserialize from D:\\Python\\notebook\\restful\\repo/foo-bar/movielens_recommendation/data/parsed.yaml\n",
      "2018-03-13 10:41:29,743 - Loader - INFO [line:451] - try to restful transform ... \n",
      "INFO:tensorflow:Calling model_fn.\n",
      "2018-03-13 10:41:29,817 - tensorflow - INFO [line:116] - Calling model_fn.\n",
      "2018-03-13 10:41:29,818 - ModelMfDNN - INFO [line:26] - mode = infer\n",
      "WARNING:tensorflow:From D:/Python/notebook/restful\\recomm\\trainer\\reco_mf_dnn_est.py:76: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "2018-03-13 10:41:30,090 - tensorflow - WARNING [line:126] - From D:/Python/notebook/restful\\recomm\\trainer\\reco_mf_dnn_est.py:76: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "2018-03-13 10:41:30,111 - tensorflow - INFO [line:116] - Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "2018-03-13 10:41:30,254 - tensorflow - INFO [line:116] - Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from D:\\Python\\notebook\\restful\\repo/foo-bar/movielens_recommendation/model\\model.ckpt-600\n",
      "2018-03-13 10:41:32,117 - tensorflow - INFO [line:116] - Restoring parameters from D:\\Python\\notebook\\restful\\repo/foo-bar/movielens_recommendation/model\\model.ckpt-600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "2018-03-13 10:41:32,324 - tensorflow - INFO [line:116] - Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "2018-03-13 10:41:32,331 - tensorflow - INFO [line:116] - Done running local_init_op.\n",
      "[0.4311 0.8514 0.7644 0.9269 0.7487]\n"
     ]
    }
   ],
   "source": [
    "utils = reload('recomm.trainer.utils.utils')\n",
    "env = reload('recomm.trainer.env')\n",
    "flex = reload('recomm.trainer.utils.flex')\n",
    "est = reload('recomm.trainer.reco_mf_dnn_est')\n",
    "service = reload('recomm.trainer.service')\n",
    "\n",
    "ctrl = reload('recomm.trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': 'D:/Python/notebook/restful/repo/user_supplied/movielens.local.yaml', \n",
    "          'is_local': True, 'json_data': restful_data((22,))}\n",
    "r = ctrl.est_predict(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-13 18:13:13,810 - Ctrl - INFO [line:299] - test req: {'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml'}\n",
      "conf_path             gs://movielens-foo/user_supplied/movielens.yaml\n",
      "pid                                                           foo-bar\n",
      "raw_dir                         gs://movielens-foo/user_supplied/raws\n",
      "model_id                                     movielens_recommendation\n",
      "runtime_version                                                   1.4\n",
      "repo                 gs://recomm-job/foo-bar/movielens_recommendation\n",
      "job_dir             gs://recomm-job/foo-bar/movielens_recommendati...\n",
      "data_dir            gs://recomm-job/foo-bar/movielens_recommendati...\n",
      "deploy_path         gs://recomm-job/foo-bar/movielens_recommendati...\n",
      "parsed_conf_path    gs://recomm-job/foo-bar/movielens_recommendati...\n",
      "train_file          gs://recomm-job/foo-bar/movielens_recommendati...\n",
      "valid_file          gs://recomm-job/foo-bar/movielens_recommendati...\n",
      "export_name                                            export_foo-bar\n",
      "eval_name                                                     foo-bar\n",
      "dtype: object\n",
      "\n",
      "id\n",
      "query_movie_ids        True\n",
      "genres                 True\n",
      "avg_rating            False\n",
      "year                  False\n",
      "candidate_movie_id    False\n",
      "rating                False\n",
      "dtype: bool\n",
      "OrderedDict([('query_movie_ids', [None]), ('genres', [None]), ('avg_rating', []), ('year', []), ('candidate_movie_id', []), ('rating', [])])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The two structures don't have the same sequence length. Input structure has length 6, while shallow structure has length 8.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-8d32c068bf4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'conf_path'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'gs://movielens-foo/user_supplied/movielens.yaml'\u001b[0m\u001b[1;33m}\u001b[0m \u001b[1;31m# 'json_data': restful_data((22,))\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'D:/Python/notebook/restful/repo/foo-bar/movielens_recommendation/data/data.vl'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# D:/Python/notebook/restful/repo/foo-bar/movielens_recommendation/data/data.vl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:/Python/notebook/restful\\recomm\\trainer\\reco_mf_dnn_est.py\u001b[0m in \u001b[0;36m_input_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m                 dataset = dataset.padded_batch(n_batch,\n\u001b[1;32m--> 280\u001b[1;33m                             OrderedDict(zip(cols, tuple([None] if e else [] for e in has_multi))))\n\u001b[0m\u001b[0;32m    281\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                 \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mpadded_batch\u001b[1;34m(self, batch_size, padded_shapes, padding_values)\u001b[0m\n\u001b[0;32m    771\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    772\u001b[0m     \"\"\"\n\u001b[1;32m--> 773\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mPaddedBatchDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadded_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    774\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    775\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, batch_size, padded_shapes, padding_values)\u001b[0m\n\u001b[0;32m   1490\u001b[0m         if padding_values is not None else _default_padding(input_dataset))\n\u001b[0;32m   1491\u001b[0m     self._padded_shapes = nest.map_structure_up_to(\n\u001b[1;32m-> 1492\u001b[1;33m         input_dataset.output_shapes, _partial_shape_to_tensor, padded_shapes)\n\u001b[0m\u001b[0;32m   1493\u001b[0m     self._padding_values = nest.map_structure_up_to(\n\u001b[0;32m   1494\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_padding_value_to_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure_up_to\u001b[1;34m(shallow_tree, func, *inputs)\u001b[0m\n\u001b[0;32m    529\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot map over no sequences\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0minput_tree\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m     \u001b[0massert_shallow_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshallow_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m   \u001b[1;31m# Flatten each input separately, apply the function to corresponding elements,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\Anaconda3\\envs\\py3_5\\lib\\site-packages\\tensorflow\\python\\data\\util\\nest.py\u001b[0m in \u001b[0;36massert_shallow_structure\u001b[1;34m(shallow_tree, input_tree, check_types)\u001b[0m\n\u001b[0;32m    375\u001b[0m           \u001b[1;34m\"The two structures don't have the same sequence length. Input \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m           \u001b[1;34m\"structure has length %s, while shallow structure has length %s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m           % (len(input_tree), len(shallow_tree)))\n\u001b[0m\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheck_types\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshallow_tree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The two structures don't have the same sequence length. Input structure has length 6, while shallow structure has length 8."
     ]
    }
   ],
   "source": [
    "utils = reload('recomm.trainer.utils.utils')\n",
    "env = reload('recomm.trainer.env')\n",
    "flex = reload('recomm.trainer.utils.flex')\n",
    "est = reload('recomm.trainer.reco_mf_dnn_est')\n",
    "service = reload('recomm.trainer.service')\n",
    "\n",
    "ctrl = reload('recomm.trainer.ctrl').Ctrl.instance\n",
    "params = {'conf_path': 'gs://movielens-foo/user_supplied/movielens.yaml'} # 'json_data': restful_data((22,))\n",
    "r = ctrl.test(params)\n",
    "r.input_fn(['D:/Python/notebook/restful/repo/foo-bar/movielens_recommendation/data/data.vl'])() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更改GCS movielens.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from google.cloud.storage.blob import Blob\n",
    "from io import BytesIO\n",
    "\n",
    "utils = reload('recomm.trainer.utils.utils')\n",
    "flex = reload('recomm.trainer.utils.flex')\n",
    "env = reload('recomm.trainer.env')\n",
    "\n",
    "with flex.io('../data/foo/user_supplied/movielens.yaml') as r, \\\n",
    "    flex.io('gs://movielens-foo/user_supplied/movielens.yaml') as w:\n",
    "    w.write(r.read())\n",
    "\n",
    "# stream = BytesIO(open('../data/foo/user_supplied/movielens.yaml', mode='rb').read())\n",
    "# utils.gcs_blob('gs://movielens-foo/user_supplied/movielens.yaml').upload_from_file(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_datasets(fpath_ary, schema, n_batch=128, n_epoch=1):\n",
    "    def to_dense(sp):\n",
    "        dense = tf.sparse_to_dense(sp.indices, sp.dense_shape, sp.values, '')\n",
    "        return tf.reshape(tf.to_int32(tf.string_to_number(dense)), [-1])\n",
    "\n",
    "    def to_sparse(dense):\n",
    "        idx = tf.where(tf.not_equal(dense, 0))\n",
    "        return tf.SparseTensor(indices=idx, dense_shape=dense.get_shape(), values=tf.gather_nd(dense, idx))\n",
    "\n",
    "    def parse_csv(value):\n",
    "        data = tf.decode_csv(value, record_defaults=defaults)\n",
    "        features = OrderedDict(zip(cols, data))\n",
    "        multi_cols = df_conf.query(\"{} == '{}' and {} == True\".format(schema.M_DTYPE, schema.CATG, schema.IS_MULTI)).id.values\n",
    "        for col in multi_cols:\n",
    "            features[col] = tf.string_split([features[col]], ',')\n",
    "            features[col] = to_dense(features[col])\n",
    "            # features['{}_lens'.format(col)] = tf.size(features[col])\n",
    "        return features \n",
    "    \n",
    "    df_conf = schema.df_conf_.query('{}.notnull()'.format(schema.TYPE))\n",
    "    cols = schema.cols\n",
    "    defaults = []\n",
    "    for _, r in df_conf.iterrows():\n",
    "        if r[schema.M_DTYPE] == schema.CATG:\n",
    "            defaults.append([''] if r[schema.IS_MULTI] else [0])\n",
    "        else:\n",
    "            defaults.append([])\n",
    "    dataset = tf.data.TextLineDataset(fpath_ary)\n",
    "    dataset = dataset.map(parse_csv, num_parallel_calls=4)\n",
    "    has_multi = (df_conf[schema.M_DTYPE] == schema.CATG) & (df_conf[schema.IS_MULTI] == True)\n",
    "    if sum(has_multi):\n",
    "        multi_cols = df_conf[has_multi].id.values\n",
    "        dataset = dataset.padded_batch(n_batch, OrderedDict( zip(cols, tuple([None] if e else [] for e in has_multi))) )\n",
    "    else:\n",
    "        dataset = dataset.batch(n_batch)\n",
    "    dataset = dataset.shuffle(n_batch * 10, seed=seed).repeat(n_epoch)\n",
    "    features = dataset.make_one_shot_iterator().get_next()\n",
    "    return features, features.pop(schema.label[0])\n",
    "                                \n",
    "# tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    inputs = make_datasets(['./movielens.tr'], loader.schema, n_batch=30)\n",
    "    query_lens = tf.sequence_mask([1, 2, 3])\n",
    "    ctx = []\n",
    "    with tf.train.MonitoredTrainingSession() as sess:\n",
    "        while not sess.should_stop():\n",
    "            _, = sess.run([inputs])\n",
    "            # print( sess.run(inputs) )\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Columns with tf.feature_column.input_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = pd.Series(minmax_scale(np.random.normal(0, 1, size=1000)))\n",
    "a.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    user_id = tf.feature_column.categorical_column_with_hash_bucket('user_id', hash_bucket_size=1000, dtype=tf.int32)\n",
    "    user_id = tf.feature_column.embedding_column(user_id, dimension=8)\n",
    "    avg_rating = tf.feature_column.numeric_column('avg_rating')\n",
    "    columns = [user_id, avg_rating]\n",
    "    \n",
    "    def make_datasets(fpath_ary):\n",
    "        cols = ['user_id', 'query_movie_ids', 'genres', 'avg_rating', 'year', 'candidate_movie_id', 'rating']\n",
    "        defaults = [[0], [''], [''], [], [], [0], []]\n",
    "\n",
    "        def parse_csv(value):\n",
    "            data = tf.decode_csv(value, record_defaults=defaults)\n",
    "            features = OrderedDict(zip(cols, data))\n",
    "            # print(features)\n",
    "            return features\n",
    "        \n",
    "        dataset = tf.data.TextLineDataset(fpath_ary)\n",
    "        dataset = (dataset.map(parse_csv, num_parallel_calls=4)\n",
    "                          .batch(3)\n",
    "                          # .padded_batch(3, OrderedDict(zip(cols, ([], [None], [None], [], [], [], []))))\n",
    "                          .shuffle(10, seed=seed)\n",
    "                          .repeat(1)\n",
    "                  )\n",
    "        return dataset.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    inputs = make_datasets(['./te_processed.batch.csv'])\n",
    "    inputs = tf.feature_column.input_layer(inputs, columns)\n",
    "    # features = tf.parse_example(serialized_example, features=tf.feature_column.make_parse_example_spec(columns))\n",
    "    ctx = []\n",
    "    with tf.train.MonitoredTrainingSession() as sess:\n",
    "        while not sess.should_stop():\n",
    "            print(sess.run(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Make Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "cols = ['user_id', 'query_movie_ids', 'genres', 'avg_rating', 'year', 'candidate_movie_id', 'rating']\n",
    "is_multi = [False, True, True, False, False, False, False]\n",
    "pd_dtypes = [int, str, str, float, float, int, float]\n",
    "types = ['int64_list', 'int64_list', 'int64_list', 'float_list', 'float_list', 'int64_list', 'float_list']\n",
    "tf_types = [tf.int64, tf.int64, tf.int64, tf.float32, tf.float32, tf.int64, tf.float32]\n",
    "def persist_example(fpath, tfpath):\n",
    "    with tf.python_io.TFRecordWriter(tfpath) as w:\n",
    "        for chunk in pd.read_csv(fpath, names=cols, dtype=dict(zip(cols, pd_dtypes)), chunksize=1000):\n",
    "            chunk['query_movie_ids'] = chunk.query_movie_ids.map(lambda r: map(int, r.split(',')))\n",
    "            chunk['genres'] = chunk.genres.map(lambda r: map(int, r.split(',')))\n",
    "            \n",
    "            for idx, r in chunk.iterrows():\n",
    "                ex = tf.train.Example()\n",
    "                for multi, col, tpe in zip(is_multi, cols, types):\n",
    "                    val = r[col]\n",
    "                    # ex.features.feature[col].int64_list or float_list or bytes_list\n",
    "                    feat_type = getattr(ex.features.feature[col], tpe)\n",
    "                    # extend function for multivalent columns, otherwise append\n",
    "                    append_or_extend = 'append' if not multi else 'extend'                    \n",
    "                    getattr(feat_type.value, append_or_extend)(val)\n",
    "                w.write(ex.SerializePartialToString())\n",
    "\n",
    "persist_example('./te_processed.csv', './data.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_example(ser_example):\n",
    "    # queue = tf.train.string_input_producer([fpath], num_epochs=1)\n",
    "    # _, ser_example = tf.TFRecordReader().read(queue)\n",
    "    # ser_example = tf.train.batch([ser_example], batch_size=10)\n",
    "    ctx_features = {col: tf.FixedLenFeature([], tf_tpe)\n",
    "                    for col, tf_tpe in zip(cols, tf_types) if col not in ('query_movie_ids', 'genres')}\n",
    "    seq_features = {col: tf.FixedLenSequenceFeature([], tf_tpe) \n",
    "                    for col, tf_tpe in [('query_movie_ids', tf.int64), ('genres', tf.int64)]}\n",
    "    context_dict, sequence_dict = tf.parse_single_sequence_example(ser_example, \n",
    "                                                                   context_features=ctx_features, \n",
    "                                                                   sequence_features=seq_features)\n",
    "    # for col, tpe in zip(cols, tf_types):\n",
    "    #     val = feature_dict[col]\n",
    "    #     feature_dict[col] = tf.sparse_to_dense(val.indices, val.dense_shape, val.values, name=col)\n",
    "    feature_dict = {}\n",
    "    feature_dict.update(context_dict)\n",
    "    feature_dict.update(sequence_dict)\n",
    "    ret = OrderedDict()\n",
    "    for c in cols:\n",
    "        ret[c] = feature_dict[c]\n",
    "    return tuple(ret.values())\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    dataset = tf.data.TFRecordDataset(['./data.tfrecord'])\n",
    "    dataset = dataset.map(decode_example).padded_batch(10, padded_shapes=([], [None], [None], [], [], [], []))\n",
    "    # dataset = dataset.batch(3)\n",
    "    iters = dataset.make_one_shot_iterator()\n",
    "    r = iters.get_next()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        print( sess.run(r) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional parse_example\n",
    "1. tf.train.Coordinator + tf.train.start_queue_runners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import sparse_tensor\n",
    "import re\n",
    "\n",
    "def to_sparse(dense):\n",
    "    idx = tf.where(tf.not_equal(dense, 0))\n",
    "    return tf.SparseTensor(idx, tf.gather_nd(dense, idx), dense.get_shape())\n",
    "\n",
    "def make_example(val):\n",
    "    example = tf.train.Example(features=tf.train.Features(\n",
    "        feature = {\n",
    "            'query_movie_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=val)),\n",
    "            'genres': tf.train.Feature(int64_list=tf.train.Int64List(value=val))\n",
    "        }\n",
    "    ))\n",
    "    return example\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    filename = \"tmp.tfrecords\"\n",
    "    if not os.path.exists(filename):\n",
    "        # os.remove(filename)\n",
    "        writer = tf.python_io.TFRecordWriter(filename)\n",
    "        with writer:\n",
    "            for idx, r in teProcessed.head().iterrows():\n",
    "                for col in ('query_movie_ids', 'genres'):\n",
    "                    val = list(map(int, re.split(',\\s*', r[col])))\n",
    "                    ex = make_example(val)\n",
    "                    writer.write(ex.SerializeToString())\n",
    "\n",
    "    reader = tf.TFRecordReader()\n",
    "    filename_queue = tf.train.string_input_producer([\"tmp.tfrecords\"], num_epochs=1)\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "    batch = tf.train.batch(tensors=[serialized_example], batch_size=1)\n",
    "    features = {\n",
    "        'query_movie_ids': tf.VarLenFeature(tf.int64),\n",
    "        'genres': tf.VarLenFeature(tf.int64)\n",
    "    }\n",
    "    data = tf.parse_example(batch, features)\n",
    "    query_movie_ids = data['query_movie_ids']\n",
    "    embbedding = tf.Variable(tf.glorot_uniform_initializer()([9125]), dtype=tf.float32)\n",
    "    print(query_movie_ids.dense_shape)\n",
    "    # r = tf.layers.dense(query_movie_ids, 10)\n",
    "    # emb_query = tf.nn.embedding_lookup_sparse([embbedding], query_movie_ids, None, combiner='sqrtn')\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        tf.local_variables_initializer().run()\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord, sess=sess)\n",
    "        try:\n",
    "            print(sess.run(data))\n",
    "            pass\n",
    "        except tf.errors.OutOfRangeError as e:\n",
    "            coord.request_stop(e)\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Graph().as_default():\n",
    "    # a = tf.constant([[0, 1], [0, 2]])\n",
    "    # w = tf.constant([[1, 1, 1],\n",
    "    #                  [2, 2, 2],\n",
    "    #                  [3, 3, 3]])\n",
    "    # w1 = tf.constant([[1, 1, 1],\n",
    "    #                   [2, 2, 2],\n",
    "    #                   [3, 3, 3]])\n",
    "    # c = tf.nn.embedding_lookup(w, a)\n",
    "    print(tf.constant([1, 2, 3]))\n",
    "    with tf.Session() as sess:\n",
    "        tf.global_variables_initializer().run()\n",
    "        # print(tf.size(tf.constant([1, 2, 3])).eval())\n",
    "        # print((w * w1).eval())\n",
    "        # print(c.eval())\n",
    "        # print(tf.sequence_mask(tf.constant([[1], [2], [3]])).eval())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
